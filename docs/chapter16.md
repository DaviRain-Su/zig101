# 第16章 Zig中的线程和并行性介绍 - Zig入门介绍

线程在Zig中通过Zig标准库中的`Thread`结构体提供。这个结构体代表一个内核线程，它遵循POSIX线程模式，意味着它的工作方式类似于C语言`pthread`库中的线程，该库通常在GNU C编译器（`gcc`）的任何发行版中都可用。如果你不熟悉线程，我先给你介绍一些背后的理论，好吗？

## 什么是线程？

线程基本上是一个独立的执行上下文。我们使用线程来为程序引入并行性，在大多数情况下，这使程序运行得更快，因为我们有多个任务同时并行执行。

程序默认通常是单线程的。这意味着每个程序通常在单个线程或单个执行上下文上运行。当我们只有一个线程运行时，我们没有并行性。当我们没有并行性时，命令是顺序执行的，也就是说，一次只执行一个命令，一个接一个。通过在程序内创建多个线程，我们开始同时执行多个命令。

创建多个线程的程序在实际应用中非常常见。因为许多不同类型的应用程序都非常适合并行性。好的例子包括视频和照片编辑应用程序（例如Adobe Photoshop或DaVinci Resolve）、游戏（例如巫师3）以及网络浏览器（例如Google Chrome、Firefox、Microsoft Edge等）。例如，在网络浏览器中，线程通常用于实现标签页。网络浏览器中的标签页通常作为主浏览器进程中的独立线程运行。也就是说，你在网络浏览器中打开的每个新标签页通常在独立的执行线程上运行。

通过在独立线程中运行每个标签页，我们允许浏览器中所有打开的标签页同时运行，并且彼此独立。例如，你可能当前在一个标签页中打开了YouTube或Spotify，你在该标签页中听一些播客，同时在另一个标签页中工作，在Google Docs上写文章。即使你没有看YouTube标签页，你仍然能听到播客，这只是因为这个YouTube标签页与运行Google Docs的另一个标签页并行运行。

如果没有线程，另一种选择是将每个标签页作为计算机中完全独立的进程运行。但这将是一个糟糕的选择，因为仅仅几个标签页就会消耗计算机太多的能量和资源。换句话说，与创建新的执行线程相比，创建一个全新的进程非常昂贵。此外，你在使用浏览器时遇到延迟和开销的可能性会很大。线程创建速度更快，它们消耗的计算机资源也少得多，特别是因为它们与主进程共享一些资源。

因此，正是在现代网络浏览器中使用线程，才能让你在Google Docs上写东西的同时听播客。没有线程，网络浏览器可能只能限于一个标签页。

线程也非常适合处理请求或订单的任何事情。因为服务请求需要时间，通常涉及大量的"等待时间"。换句话说，我们花很多时间空闲，等待某些事情完成。例如，考虑一家餐厅。在餐厅服务订单通常涉及以下步骤：

1. 从客户那里接收订单。
2. 将订单传递给厨房，等待食物烹饪。
3. 开始在厨房烹饪食物。
4. 当食物完全烹饪好后，将食物送给客户。

如果你思考上面的要点，你会注意到在整个过程中存在一个很大的等待时间，那就是食物在厨房烹饪的时候。当食物正在准备时，服务员和客户本身都在等待食物准备好并送达。

如果我们编写一个程序来代表这家餐厅，更具体地说，一个单线程程序，那么这个程序将非常低效。因为程序会在"检查食物是否准备好"这一步上空闲，等待相当长的时间。考虑下面展示的代码片段，它可能代表这样的程序。

这个程序的问题是while循环。这个程序将花费大量时间在while循环上等待，除了检查食物是否准备好之外什么都不做。这是时间的浪费。服务员可以将订单发送到厨房，然后继续前进，继续接收其他客户的更多订单，并向厨房发送更多订单，而不是什么都不做，等待食物准备好。

```zig
const order = Order.init("Pizza Margherita", n = 1);
const waiter = Waiter.init();
waiter.receive_order(order);
waiter.ask_kitchen_to_cook();
var food_not_ready = true;
while (food_not_ready) {
    food_not_ready = waiter.is_food_ready();
}
const food = waiter.get_food_from_kitchen();
waiter.send_food_to_client(food);
```

这就是为什么线程非常适合这个程序。我们可以使用线程来解放服务员的"等待职责"，这样他们就可以继续执行其他任务，并接收更多订单。看看下一个例子，我已经将上面的程序重写为使用线程来烹饪和交付订单的不同程序。

你可以在这个程序中看到，当服务员从客户那里收到新订单时，该服务员执行`send_order()`函数。这个函数唯一做的事情就是创建一个新线程并分离它。由于创建线程是一个非常快的操作，这个`send_order()`函数几乎立即返回，所以服务员几乎不花时间担心订单，只是继续前进并尝试从客户那里获取下一个订单。

在创建的新线程内部，订单由厨师烹饪，当食物准备好时，它被送到客户的桌子上。

```zig
fn cook_and_deliver_order(order: *Order) void {
    const chef = Chef.init();
    const food = chef.cook(order.*);
    chef.deliver_food(food);
}
fn send_order(order: Order) void {
    const cook_thread = Thread.spawn(
        .{}, cook_and_deliver_order, .{&order}
    );
    cook_thread.detach();
}

const waiter = Waiter.init();
while (true) {
    const order = waiter.get_new_order();
    if (order) {
        send_order(order);
    }
}
```

## 线程与进程

当我们运行一个程序时，这个程序在操作系统中作为一个_进程_执行。这是一对一的关系，你执行的每个程序或应用程序都是操作系统中的一个独立进程。但每个程序或每个进程可以在其内部创建并包含多个线程。因此，进程和线程具有一对多的关系。

这也意味着我们创建的每个线程始终与计算机中的特定进程相关联。换句话说，线程始终是现有进程的子集（或子级）。所有线程共享与创建它们的进程相关联的一些资源。因为线程与进程共享资源，它们非常适合使任务之间的通信更容易。

例如，假设你正在开发一个大型复杂的应用程序，如果你能将其分成两部分，并让这两个独立的部分相互通信，会简单得多。一些程序员选择有效地将代码库的这两部分编写为两个完全独立的程序，然后使用IPC（_进程间通信_）使这两个独立的程序/进程相互通信，并使它们协同工作。

然而，一些程序员发现IPC难以处理，因此，他们更喜欢将代码库的一部分编写为"程序的主要部分"，或者作为在操作系统中作为进程运行的代码部分，而代码库的另一部分则编写为要在新线程中执行的任务。进程和线程可以通过控制流以及数据轻松地相互通信，因为它们共享并可以访问相同的标准文件描述符（`stdout`、`stdin`、`stderr`），以及堆和全局数据部分中的相同内存空间。

更详细地说，你创建的每个线程都有一个专门为该线程保留的独立栈帧，这本质上意味着你在此线程内创建的每个局部对象都是该线程的局部对象，即其他线程无法看到此局部对象。除非你创建的这个对象是存在于堆上的对象。换句话说，如果与此对象关联的内存在堆上，那么其他线程可能可以访问此对象。

因此，存储在栈中的对象是创建它们的线程的局部对象。但存储在堆上的对象可能可以被其他线程访问。所有这些都意味着，每个线程都有自己独立的栈帧，但同时，所有线程共享相同的堆、相同的标准文件描述符（这意味着它们共享相同的`stdout`、`stdin`、`stderr`），以及程序中相同的全局数据部分。

## 创建线程

我们在Zig中通过首先将`Thread`结构体导入到当前Zig模块中，然后调用这个结构体的`spawn()`方法来创建新线程，该方法从我们当前的进程创建（或"生成"）一个新的执行线程。这个方法有三个参数，分别是：

1. 一个`SpawnConfig`对象，包含生成过程的配置。
2. 将在这个新线程内执行（或将被"调用"）的函数的名称。
3. 要传递给第二个参数中提供的函数的参数（或输入）列表。

通过这三个参数，你可以控制线程的创建方式，并指定将在这个新线程内执行哪些工作（或"任务"）。线程只是一个独立的执行上下文，我们通常在代码中创建新线程是因为我们想在这个新的执行上下文中执行一些工作。我们通过提供函数名称作为`spawn()`方法的第二个参数来指定将在此上下文中执行的确切工作或确切步骤。

因此，当创建这个新线程时，你作为输入提供给`spawn()`方法的这个函数会被调用，或在这个新线程内执行。你可以通过在`spawn()`方法的第三个参数中提供参数列表（或输入列表）来控制当这个函数被调用时传递给它的参数或输入。这些参数按照提供给`spawn()`的相同顺序传递给函数。

此外，`SpawnConfig`是一个只有两个可能字段或两个可能成员的结构体对象，你可以设置它们来定制生成行为。这些字段是：

* `stack_size`：你可以提供一个`usize`值来指定线程栈帧的大小（以字节为单位）。默认情况下，此值为：16 × 1024 × 1024。
* `allocator`：你可以提供一个分配器对象，用于为线程分配内存时使用。

要使用这两个字段（或"配置"）之一，你只需创建一个类型为`SpawnConfig`的新对象，并将此对象作为输入提供给`spawn()`方法。但是，如果你对使用这些配置之一不感兴趣，并且你可以接受使用默认值，你可以在这个`SpawnConfig`参数的位置提供一个匿名结构字面量（`.{}`）。

作为我们第一个非常简单的例子，考虑下面展示的代码。在同一个程序中，如果你愿意，你可以创建多个执行线程。但是，在这第一个例子中，我们只创建一个执行线程，因为我们只调用`spawn()`一次。

另外，注意在这个例子中，我们在新线程内执行函数`do_some_work()`。由于这个函数不接收输入，因为它没有参数，我们在这个实例中传递了一个空列表，或者更准确地说，在`spawn()`的第三个参数中传递了一个空的匿名结构（`.{}`）。

```zig
const std = @import("std");
var stdout_buffer: [1024]u8 = undefined;
var stdout_writer = std.fs.File.stdout().writer(&stdout_buffer);
const stdout = &stdout_writer.interface;
const Thread = std.Thread;

fn do_some_work() !void {
    _ = try stdout.write("Starting the work.\n");
    try stdout.flush();
    Thread.sleep(1000 * std.time.ns_per_ms);
    _ = try stdout.write("Finishing the work.\n");
    try stdout.flush();
}

pub fn main() !void {
    const thread = try Thread.spawn(.{}, do_some_work, .{});
    thread.join();
}
```

```
Starting the work.
Finishing the work.
```

注意调用`spawn()`方法时使用了`try`。这意味着这个方法在某些情况下可能返回错误。特别是当你尝试创建新线程时，而你已经创建了太多线程（即你已经超过了系统中并发线程的配额）。

但是，如果新线程成功创建，`spawn()`方法会返回这个新线程的处理器对象（这只是一个类型为`Thread`的对象）。你可以使用这个处理器对象来有效地控制线程的所有方面。

当线程被创建时，你作为输入提供给`spawn()`的函数会被调用（即被调用）以在这个新线程上开始执行。换句话说，每次你调用`spawn()`时，不仅创建了一个新线程，而且这个线程的"开始工作按钮"也会自动按下。所以在这个线程中执行的工作在线程创建后立即开始。这类似于C中`pthreads`库的`pthread_create()`的工作方式，它也在线程创建后立即开始执行。

## 从线程返回

我们在前一节中了解到，线程的执行在线程创建后立即开始。现在，我们将学习如何在Zig中"加入"或"分离"线程。"加入"和"分离"是控制线程如何返回到主线程或程序中主进程的操作。

我们通过使用线程处理器对象的`join()`和`detach()`方法来执行这些操作。你创建的每个线程都可以标记为_可加入_或_分离_（[Linux man-pages 2024](https://pedropark99.github.io/zig-book/Chapters/references.html#ref-linux_pthread_create)）。你可以通过从线程处理器对象调用`detach()`方法将线程转换为_分离_线程。但如果你调用`join()`方法，那么这个线程就变成了_可加入_线程。

线程不能既是_可加入_又是_分离_的。这通常意味着你不能在同一个线程上同时调用`join()`和`detach()`。但线程必须是两者之一，这意味着你应该始终在线程上调用`join()`或`detach()`之一。如果你不在线程上调用这两个方法之一，你会在程序中引入未定义行为，这在[第16.9.2节](https://pedropark99.github.io/zig-book/Chapters/14-threads.html#sec-not-call-join-detach)中描述。

现在，让我们描述这两个方法对你的线程做了什么。

### 加入线程

当你加入一个线程时，你本质上是在说："嘿！你能在继续执行之前等待线程完成吗？"。例如，如果我们回到Zig中线程的第一个最简单的例子，我们在程序的`main()`函数内创建了一个线程，并在最后对这个线程调用了`join()`。代码示例的这一部分在下面重现。

因为我们在`main()`的作用域内加入这个新线程，这意味着`main()`函数的执行会暂时停止，等待线程执行完成。也就是说，`main()`的执行在调用`join()`的行暂时停止，只有在线程完成其任务后才会继续。

```zig
pub fn main() !void {
    const thread = try Thread.spawn(.{}, do_some_work, .{});
    thread.join();
}
```

因为我们在`main()`作用域内加入了这个新线程，我们保证这个新线程将在`main()`执行结束之前完成。因为保证`main()`会等待线程完成其任务。

在上面的例子中，`join()`调用后没有更多的表达式。我们只有`main()`作用域的结束，因此，我们程序的执行在线程完成其任务后就结束了，因为没有更多的事情要做。但如果我们在join调用后还有更多的事情要做呢？

为了演示这种其他可能性，考虑下面展示的下一个例子。在这里，我们创建了一个`print_id()`函数，它只是接收一个id作为输入，并将其打印到`stdout`。在这个例子中，我们一个接一个地创建两个新线程。然后，我们加入第一个线程，然后等待整整两秒，最后加入第二个线程。

这个例子背后的想法是，最后的`join()`调用只在第一个线程完成其任务（即第一个`join()`调用）和两秒延迟之后执行。如果你编译并运行这个例子，你会注意到大多数消息很快打印到`stdout`，即它们几乎立即出现在你的屏幕上。然而，最后一条消息（"Joining thread 2"）大约需要2秒才能出现在屏幕上。

```zig
fn print_id(id: *const u8) !void {
    try stdout.print("Thread ID: {d}\n", .{id.*});
    try stdout.flush();
}

pub fn main() !void {
    const id1: u8 = 1;
    const id2: u8 = 2;
    const thread1 = try Thread.spawn(.{}, print_id, .{&id1});
    const thread2 = try Thread.spawn(.{}, print_id, .{&id2});

    _ = try stdout.write("Joining thread 1\n");
    try stdout.flush();
    thread1.join();

    Thread.sleep(2 * std.time.ns_per_s);

    _ = try stdout.write("Joining thread 2\n");
    try stdout.flush();
    thread2.join();
}
```

```
Thread ID: Joining thread 1
1
Thread ID: 2
Joining thread 2
```

这表明两个线程都非常快地完成了它们的工作（即打印ID），在两秒延迟结束之前。因此，最后的`join()`调用几乎立即返回。因为当最后的`join()`调用发生时，第二个线程已经完成了它的任务。

现在，如果你编译并运行这个例子，你还会注意到，在某些情况下，消息会相互交织。换句话说，你可能会看到消息"Joining thread 1"插入到消息"Thread 1"的中间，反之亦然。这是因为：

* 线程基本上与程序的主进程（即`main()`函数）同时执行。
* 线程与程序的主进程共享相同的`stdout`，这意味着线程产生的消息被发送到与主进程产生的消息完全相同的地方。

这两点都在[第16.1节](https://pedropark99.github.io/zig-book/Chapters/14-threads.html#sec-what-thread)中描述过。所以消息可能会交织，因为它们大致在同一时间被产生并发送到相同的`stdout`。无论如何，当你对线程调用`join()`时，当前进程将等待线程完成后再继续，当线程完成其任务时，与此线程关联的资源会自动释放，当前进程继续执行。

### 分离线程

当你分离一个线程时，与此线程关联的资源会自动释放回系统，而不需要另一个线程与这个终止的线程加入。

换句话说，当你对线程调用`detach()`时，就像你的孩子成年了，即他们独立于你。分离的线程会自己释放自己，当这个线程完成其任务时，它不会向你报告结果。因此，当你不需要使用线程的返回值，或者当你不关心线程确切何时完成其工作时，你通常将线程标记为_分离_，即线程自己解决一切。

看看下面的代码示例。我们创建一个新线程，分离它，然后在结束程序之前打印最后一条消息。我们使用与前面例子中使用的相同的`print_id()`函数。

```zig
fn print_id(id: *const u8) !void {
    try stdout.print("Thread ID: {d}\n", .{id.*});
    try stdout.flush();
}

pub fn main() !void {
    const id1: u8 = 1;
    const thread1 = try Thread.spawn(.{}, print_id, .{&id1});
    thread1.detach();
    _ = try stdout.write("Finish main\n");
    try stdout.flush();
}
```

```
Finish main
```

现在，如果你仔细查看这个代码示例的输出，你会注意到只有main中的最后一条消息被打印到控制台。`print_id()`应该打印的消息没有出现在控制台中。为什么？这是因为我们程序的主进程先结束了，在线程能够说任何话之前。

这是完全正常的行为，因为线程被分离了，所以它能够自己释放自己，而不需要等待主进程。如果你要求main睡眠（或"等待"）一些额外的纳秒，在它结束之前，你可能会看到`print_id()`打印的消息，因为你给了线程足够的时间在主进程结束之前完成。

## 线程池

线程池是一种非常流行的编程模式，特别是在服务器和守护进程中使用。线程池只是一组线程，或者线程的"池"。许多程序员喜欢使用这种模式，因为它使得在程序中管理和使用多个线程变得更容易，而不是在需要时手动创建线程。

此外，在你的程序中使用线程池也可能提高性能，特别是如果你的程序不断创建线程来执行短期任务。在这种情况下，线程池可能会导致性能提升，因为你不必一直不断地创建和销毁线程，所以你不会面临这种不断创建和销毁线程过程中涉及的大量开销。

线程池背后的主要思想是拥有一组已经创建并随时准备执行任务的线程。你在程序启动时创建一组线程，并在程序运行时保持这些线程活动。这些线程中的每一个要么正在执行任务，要么正在等待分配任务。每当程序中出现新任务时，这个任务就会被添加到"任务队列"中，当一个线程变得可用并准备执行新任务时，这个线程从"任务队列"中获取下一个任务，并简单地执行任务。

Zig标准库在`std.Thread.Pool`结构体上提供了线程池实现。你通过向这个结构体的`init()`方法提供`Pool.Options`对象作为输入来创建`Pool`对象的新实例。`Pool.Options`对象是一个包含线程池配置的结构体对象。这个结构体对象中最重要的设置是成员`n_jobs`和`allocator`。顾名思义，成员`allocator`应该接收一个分配器对象，而成员`n_jobs`指定要在此池中创建和维护的线程数。

考虑下面展示的例子，演示了我们如何创建一个新的线程池对象。在这里，我们创建了一个包含通用目的分配器对象的`Pool.Options`对象，并且`n_jobs`成员被设置为4，这意味着线程池将创建并使用4个线程。

还要注意，`pool`对象最初被设置为`undefined`。这允许我们最初声明线程池对象，但不正确地实例化对象的底层内存。你必须像这样使用`undefined`最初声明你的线程池对象，因为`Pool`的`init()`方法需要有一个初始指针来正确实例化对象。

所以，只要记住通过使用`undefined`创建你的线程池对象，然后，之后，你对对象调用`init()`方法。你还应该记得在完成线程池对象后对其调用`deinit()`方法，以释放为线程池分配的资源。否则，你的程序中会有内存泄漏。

```zig
const std = @import("std");
const Pool = std.Thread.Pool;
pub fn main() !void {
    var gpa = std.heap.GeneralPurposeAllocator(.{}){};
    const allocator = gpa.allocator();
    const opt = Pool.Options{
        .n_jobs = 4,
        .allocator = allocator,
    };
    var pool: Pool = undefined;
    try pool.init(opt);
    defer pool.deinit();
}
```

现在我们知道如何创建`Pool`对象，我们必须了解如何分配任务由这个池对象中的线程执行。要分配要由线程执行的任务，我们需要从线程池对象调用`spawn()`方法。

这个`spawn()`方法的工作方式与`Thread`对象的`spawn()`方法相同。该方法具有与前一个几乎相同的参数，更准确地说，在这种情况下我们不必提供`SpawnConfig`对象。但是，这个线程池对象的`spawn()`方法不是创建新线程，而是只在内部"任务队列"中注册一个要执行的新任务，池中的任何可用线程都会获取这个任务，并简单地执行任务。

在下面的例子中，我们再次使用我们之前的`print_id()`函数。但你可能会注意到`print_id()`函数这次有点不同，因为现在我们在`print()`调用中使用`catch`而不是`try`。目前，`Pool`结构体只支持不返回错误的函数作为任务。因此，在将任务分配给线程池中的线程时，使用不返回错误的函数是必不可少的。这就是为什么我们在这里使用`catch`，这样`print_id()`函数就不会返回错误。

```zig
fn print_id(id: *const u8) void {
    _ = stdout.print("Thread ID: {d}\n", .{id.*})
        catch void;
}
const id1: u8 = 1;
const id2: u8 = 2;
try pool.spawn(print_id, .{&id1});
try pool.spawn(print_id, .{&id2});
```

这个限制可能不应该存在，事实上，它已经在Zig团队的雷达上要修复这个问题，并且正在[一个开放问题](https://github.com/ziglang/zig/issues/18810)中跟踪。所以，如果你确实需要提供一个可能返回错误的函数作为线程池中线程要执行的任务，那么你要么限于：

* 实现你自己的没有这个限制的线程池。
* 等待Zig团队实际修复这个问题。

## 互斥锁

互斥锁是每个线程库的经典组件。本质上，互斥锁是一个_互斥标志_，这个标志就像代码特定部分的一种"锁"或门卫。互斥锁与线程同步有关，更具体地说，它们防止你在程序中出现一些经典的竞态条件，因此，防止通常难以跟踪和理解的主要错误和未定义行为。

互斥锁背后的主要思想是帮助我们控制代码特定部分的执行，并防止两个或更多线程同时执行代码的这个特定部分。许多程序员喜欢将互斥锁比作浴室门（通常有锁）。当一个线程锁定自己的互斥锁对象时，就像浴室门被锁上了。因此，想要同时使用同一浴室的其他人（在这种情况下，其他线程）必须耐心等待当前占用者（或线程）解锁门并离开浴室。

其他一些程序员也喜欢通过使用"每个人都有发言权"的类比来解释互斥锁。这是[Computerphile项目的_多线程代码_视频](https://www.youtube.com/watch?v=7ENFeb-J75k&ab_channel=Computerphile)中使用的类比。想象你在一个对话圈中。这个圈子里有一个主持人，他是决定谁在特定时刻有权发言的人。主持人给要发言的人一张绿卡（或某种授权卡），因此，其他人必须保持沉默并听这个有绿卡的人说话。当这个人说完话后，他们把绿卡还给主持人，主持人决定谁接下来要发言，并将绿卡交给那个人。循环就这样继续下去。

互斥锁就像这个对话圈中的主持人。互斥锁授权一个线程执行代码的特定部分，它还阻止其他线程执行相同的代码部分。如果这些其他线程想要执行相同的代码片段，它们被迫等待授权线程先完成。当授权线程完成执行此代码时，互斥锁授权下一个线程执行此代码，而其余线程保持阻塞。因此，互斥锁就像一个主持人，进行"每个线程都有机会执行这部分代码"类型的控制。

互斥锁特别用于防止数据竞争问题的发生。当两个或多个线程试图同时从同一共享对象读取或写入时，就会发生数据竞争问题。因此，当你有一个与所有线程共享的对象，并且你想避免两个或多个线程同时访问同一对象时，你可以使用互斥锁来锁定访问此特定对象的代码部分。当线程尝试运行被互斥锁锁定的代码时，该线程停止执行，并耐心等待代码库的这一部分被解锁以继续。

注意，互斥锁通常用于锁定访问/修改与所有线程**共享**的数据的代码库区域，即存储在全局数据部分或程序堆空间中的对象。因此，互斥锁通常不用于访问/修改线程本地对象的代码库区域。

### 临界区

临界区是通常与互斥锁和线程同步相关的概念。本质上，临界区是线程访问/修改共享资源（即对象、文件描述符、所有线程都可以访问的东西）的程序部分。换句话说，临界区是程序中可能发生竞态条件的部分，因此，可能在程序中引入未定义行为的地方。

当我们在程序中使用互斥锁时，临界区定义了我们想要锁定的代码库区域。所以我们通常在临界区的开始锁定互斥锁对象，然后在临界区的结束解锁它。下面展示的两个要点来自GeekFromGeeks的"临界区"文章，它们很好地总结了临界区在线程同步问题中扮演的角色（[Geeks for Geeks 2024](https://pedropark99.github.io/zig-book/Chapters/references.html#ref-geeks_critical_section)）。

1. 临界区必须作为原子操作执行，这意味着一旦一个线程或进程进入临界区，所有其他线程或进程必须等待，直到执行线程或进程退出临界区。同步机制的目的是确保一次只有一个线程或进程可以执行临界区。
2. 临界区的概念是计算机系统同步的核心，因为有必要确保多个线程或进程可以并发执行而不会相互干扰。各种同步机制，如信号量、互斥锁、监视器和条件变量，用于实现临界区并确保以互斥方式访问共享资源。

### 原子操作

在阅读有关线程、竞态条件和互斥锁时，你也会经常看到"原子操作"这个术语。总的来说，当操作中间不能发生上下文切换时，操作被归类为"原子"。换句话说，这个操作总是从头到尾完成，在执行阶段中间没有其他进程或操作的中断。

今天没有多少操作是原子的。但为什么原子操作在这里很重要？这是因为数据竞争（这是竞态条件的一种类型）不能在原子操作上发生。因此，如果代码中的特定行执行原子操作，那么这一行永远不会遭受数据竞争问题。因此，程序员有时使用原子操作来保护自己免受代码中数据竞争问题的影响。

当你有一个编译成只有一条汇编指令的操作时，这个操作可能是原子的，因为它只是一条汇编指令。但这并不能保证。这通常对旧的CPU架构（如`x86`）是正确的。但如今，现代CPU架构中的大多数汇编指令都被分解为多个微任务，这本质上使操作成为非原子的，即使它由单个汇编指令组成。

Zig标准库在`std.atomic`模块中提供了一些原子功能。在这个模块中，你会找到一个名为`Value()`的公共泛型函数。使用这个函数，我们创建一个"原子对象"，它是一个包含一些原生原子操作的值，最值得注意的是`load()`和`fetchAdd()`操作。如果你有C++多线程的经验，你可能已经认识到这种模式。所以是的，Zig中的这个泛型"原子对象"本质上与C++标准库中的模板结构`std::atomic`相同。重要的是要强调，只有原始数据类型（即[第1.5节](https://pedropark99.github.io/zig-book/Chapters/01-zig-weird.html#sec-primitive-data-types)中介绍的类型）在Zig中被这些原子操作支持。

### 数据竞争和竞态条件

要理解为什么使用互斥锁，我们需要更好地理解它们寻求解决的问题，这可以总结为数据竞争问题。数据竞争问题是竞态条件的一种类型，当一个线程正在访问特定内存位置（即特定共享对象）的同时，另一个线程试图向同一内存位置（即同一共享对象）写入/保存新数据时发生。

我们可以简单地将竞态条件定义为程序中基于"谁先到达那里"问题的任何类型的错误。数据竞争问题是竞态条件的一种类型，因为它发生在两个或多个方试图同时读取和写入同一内存位置时，因此，这个操作的最终结果完全取决于谁先到达这个内存位置。因此，具有数据竞争问题的程序每次执行时可能会产生不同的结果。

因此，竞态条件产生未定义行为和不可预测性，因为每次不同的人先到达目标位置时，程序都会产生不同的答案。而且，我们没有简单的方法来预测或控制谁先到达这个目标位置。换句话说，每次你的程序运行时，你可能会得到不同的答案，因为不同的人、函数或代码部分在其他人之前完成了它的任务。

作为一个例子，考虑下面展示的代码片段。在这个例子中，我们创建了一个全局计数器变量，我们还创建了一个`increment()`函数，其工作只是在for循环中增加这个全局计数器变量。

由于for循环迭代10万次，并且我们在这个代码示例中创建了两个独立的线程，你期望在打印到`stdout`的最终消息中看到什么数字？答案应该是20万。对吗？好吧，理论上，这个程序应该在最后打印20万，但实际上，每次我执行这个程序时，我都会得到不同的答案。

在下面展示的例子中，你可以看到这次最终结果是117254，而不是预期的200000。我第二次执行这个程序时，我得到的结果是108592。所以这个程序的最终结果是变化的，但它从来没有达到我们想要的预期的200000。

```zig
// 全局计数器变量
var counter: usize = 0;
// 增加计数器的函数
fn increment() void {
    for (0..100000) |_| {
        counter += 1;
    }
}

pub fn main() !void {
    const thr1 = try Thread.spawn(.{}, increment, .{});
    const thr2 = try Thread.spawn(.{}, increment, .{});
    thr1.join();
    thr2.join();
    try stdout.print("Couter value: {d}\n", .{counter});
    try stdout.flush();
}
```

```
Couter value: 117254
```

为什么会发生这种情况？答案是：因为这个程序包含数据竞争问题。当且仅当第一个线程在第二个线程开始执行之前完成其任务时，这个程序才会打印正确的数字200000。但这不太可能发生。因为创建线程的过程太快了，因此，两个线程大致在同一时间开始执行。如果你更改此代码以在第一次和第二次调用`spawn()`之间添加一些纳秒的睡眠，你将增加程序产生"正确结果"的机会。

所以数据竞争问题发生是因为两个线程大致在同一时间读取和写入同一内存位置。在这个例子中，每个线程本质上在for循环的每次迭代中执行三个基本操作，它们是：

1. 读取`count`的当前值。
2. 将此值增加1。
3. 将结果写回`count`。

理想情况下，线程B应该只在另一个线程A完成将增加的值写回`count`对象之后读取`count`的值。因此，在理想场景中，如[表16.1](https://pedropark99.github.io/zig-book/Chapters/14-threads.html#tbl-data-race-ideal)所示，线程应该彼此同步工作。但现实是这些线程不同步，因此，它们遭受数据竞争问题，如[表16.2](https://pedropark99.github.io/zig-book/Chapters/14-threads.html#tbl-data-race-not)所示。

注意，在数据竞争场景（[表16.2](https://pedropark99.github.io/zig-book/Chapters/14-threads.html#tbl-data-race-not)）中，线程B执行的读取发生在线程A的写入操作之前，这最终导致程序结束时的错误结果。因为当线程B读取`count`变量的值时，线程A仍在处理`count`的初始值，还没有将新的增加值写回`count`。结果，线程B最终读取了`count`的相同初始（或"旧"）值，而不是线程A本应写入的更新的增加值。

表16.1：两个线程增加同一整数值的理想场景

| 线程1 | 线程2 | 整数值 |
| --- | --- | --- |
| 读取值 |  | 0 |
| 增加 |  | 1 |
| 写入值 |  | 1 |
|  | 读取值 | 1 |
|  | 增加 | 2 |
|  | 写入值 | 2 |

表16.2：两个线程增加同一整数值时的数据竞争场景

| 线程1 | 线程2 | 整数值 |
| --- | --- | --- |
| 读取值 |  | 0 |
|  | 读取值 | 0 |
| 增加 |  | 1 |
|  | 增加 | 1 |
| 写入值 |  | 1 |
|  | 写入值 | 1 |

如果你思考这些以表格形式展示的图表，你会注意到它们与我们在[第16.6.2节](https://pedropark99.github.io/zig-book/Chapters/14-threads.html#sec-atomic-operation)中讨论的原子操作有关。记住，原子操作是CPU从头到尾执行的操作，不会被其他线程或进程中断。因此，[表16.1](https://pedropark99.github.io/zig-book/Chapters/14-threads.html#tbl-data-race-ideal)中展示的场景不会遭受数据竞争，因为线程A执行的操作不会在中间被线程B的操作中断。

如果我们还考虑[第16.6.1节](https://pedropark99.github.io/zig-book/Chapters/14-threads.html#sec-critical-section)中关于临界区的讨论，我们可以识别代表程序临界区的部分，这是容易受到数据竞争条件影响的部分。在这个例子中，程序的临界区是我们增加`counter`变量的行（`counter += 1`）。因此，理想情况下，我们希望使用互斥锁，并在这一行之前锁定，然后在这一行之后解锁。

### 在Zig中使用互斥锁

现在我们知道了互斥锁寻求解决的问题，我们可以学习如何在Zig中使用它们。Zig中的互斥锁通过Zig标准库的`std.Thread.Mutex`结构体提供。如果我们采用前面例子中的相同代码，并使用互斥锁改进它，以解决我们的数据竞争问题，我们得到下面的代码示例。

注意这次我们必须修改`increment()`函数以接收指向`Mutex`对象的指针作为输入。为了使这个程序安全免受数据竞争问题的影响，我们需要做的就是在临界区的开始调用`lock()`方法，然后在临界区的结束调用`unlock()`。注意这个程序的输出现在是正确的数字200000。

```zig
const std = @import("std");
var stdout_buffer: [1024]u8 = undefined;
var stdout_writer = std.fs.File.stdout().writer(&stdout_buffer);
const stdout = &stdout_writer.interface;
const Thread = std.Thread;
const Mutex = std.Thread.Mutex;
var counter: usize = 0;
fn increment(mutex: *Mutex) void {
    for (0..100000) |_| {
        mutex.lock();
        counter += 1;
        mutex.unlock();
    }
}

pub fn main() !void {
    var mutex: Mutex = .{};
    const thr1 = try Thread.spawn(.{}, increment, .{&mutex});
    const thr2 = try Thread.spawn(.{}, increment, .{&mutex});
    thr1.join();
    thr2.join();
    try stdout.print("Couter value: {d}\n", .{counter});
    try stdout.flush();
}
```

```
Couter value: 200000
```

## 读/写锁

互斥锁通常在两个或多个线程同时运行相同代码片段并不总是安全时使用。相比之下，读/写锁通常用于混合场景的情况，即代码库的某些部分可以安全地并行运行，而其他部分则不安全。

例如，假设你有多个线程使用文件系统中的同一共享文件来存储一些配置或统计信息。如果两个或多个线程试图同时从同一文件读取数据，不会发生任何不好的事情。所以代码库的这一部分完全可以安全地并行执行，多个线程同时读取同一文件。

然而，如果两个或多个线程试图同时向同一文件写入数据，那么我们会导致一些竞态条件问题。所以代码库的这另一部分不能安全地并行执行。更具体地说，一个线程可能最终在另一个线程写入的数据中间写入数据。两个或多个线程写入同一位置的这个过程可能导致数据损坏。这种特定情况通常称为_撕裂写入_。

因此，我们可以从这个例子中提取的是，有某些类型的操作会导致竞态条件，但也有其他类型的操作不会导致竞态条件问题。你也可以说有些类型的操作容易出现竞态条件问题，而其他类型的操作则不会。

读/写锁是一种承认这种特定场景存在的锁类型，你可以使用这种类型的锁来控制代码库的哪些部分可以安全地并行运行，哪些部分不安全。

### 独占锁与共享锁

因此，读/写锁与互斥锁有点不同。因为互斥锁始终是_独占锁_，这意味着始终只允许一个线程执行。使用独占锁，其他线程总是被"排除"，即它们总是被阻止执行。但在读/写锁中，根据它们获取的锁类型，其他线程可能被授权同时运行。

我们在读/写锁中有两种类型的锁，它们是：独占锁和共享锁。独占锁的工作方式与互斥锁完全相同，而共享锁是不阻止其他线程同时运行的锁。在`pthreads` C库中，读/写锁通过`pthread_rwlock_t` C结构体提供。使用这个C结构体，你可以创建：

* "写锁"，对应于独占锁。
* "读锁"，对应于共享锁。

与Zig相比，术语可能有点不同。但含义仍然相同。因此，只要记住这种关系，写锁是独占锁，而读锁是共享锁。

当线程尝试获取读锁（即共享锁）时，当且仅当另一个线程当前没有持有写锁（即独占锁），并且队列中没有其他线程已经在等待轮到它们获取写锁时，该线程才会获得共享锁。换句话说，队列中的线程之前尝试获取写锁，但该线程被阻塞，因为有另一个已经拥有写锁的线程正在运行。因此，这个线程在队列中等待获取写锁，它目前正在等待具有写锁的另一个线程完成执行。

当线程尝试获取读锁，但由于已经有具有写锁的线程正在运行，或者因为队列中有线程要获取写锁而无法获取此读锁时，该线程的执行立即被阻塞，即暂停。这个线程将无限期地尝试获取读锁，只有在这个线程成功获取读锁后，它的执行才会被解除阻塞（或取消暂停）。

如果你深入思考读锁与写锁之间的这种动态，你可能会注意到读锁基本上是一种安全机制。更具体地说，这是我们允许特定线程仅在安全时与其他线程一起运行的一种方式。换句话说，如果当前有具有写锁的线程正在运行，那么试图获取读锁的线程现在运行很可能不安全。因此，读锁保护这个线程免于进入危险水域，并耐心等待"写锁"线程完成其任务后再继续。

另一方面，如果只有"读锁"（即"共享锁"）线程当前正在运行（即当前不存在单个"写锁"线程），那么获取读锁的这个线程与其他线程并行运行是完全安全的。结果，读锁只是允许这个线程与其他线程一起运行。

因此，通过将读锁（共享锁）与写锁（独占锁）结合使用，我们可以控制多线程代码的哪些区域或部分可以安全地具有并行性，哪些部分不能安全地具有并行性。

### 在Zig中使用读/写锁

Zig标准库通过`std.Thread.RwLock`模块支持读/写锁。如果你希望特定线程获取共享锁（即读锁），你应该从`RwLock`对象调用`lockShared()`方法。但是，如果你希望这个线程获取独占锁（即写锁），那么你应该从`RwLock`对象调用`lock()`方法。

与互斥锁一样，一旦我们在"临界区"的末尾，我们还必须解锁通过读/写锁对象获取的共享或独占锁。如果你获取了独占锁，那么，你通过从读/写锁对象调用`unlock()`方法来解锁这个独占锁。相反，如果你获取了共享锁，那么，调用`unlockShared()`来解锁这个共享锁。

作为一个简单的例子，下面的代码片段创建了三个独立的线程，负责读取`counter`对象中的当前值，它还创建了另一个线程，负责向`counter`对象写入新数据（更具体地说，增加它）。

```zig
var counter: u32 = 0;
fn reader(lock: *RwLock) !void {
    while (true) {
        lock.lockShared();
        const v: u32 = counter;
        try stdout.print("{d}", .{v});
        try stdout.flush();
        lock.unlockShared();
        Thread.sleep(2 * std.time.ns_per_s);
    }
}
fn writer(lock: *RwLock) void {
    while (true) {
        lock.lock();
        counter += 1;
        lock.unlock();
        Thread.sleep(2 * std.time.ns_per_s);
    }
}

pub fn main() !void {
    var lock: RwLock = .{};
    const thr1 = try Thread.spawn(.{}, reader, .{&lock});
    const thr2 = try Thread.spawn(.{}, reader, .{&lock});
    const thr3 = try Thread.spawn(.{}, reader, .{&lock});
    const wthread = try Thread.spawn(.{}, writer, .{&lock});

    thr1.join();
    thr2.join();
    thr3.join();
    wthread.join();
}
```

## 让出线程

`Thread`结构体通过`yield()`方法支持让出。让出线程意味着线程的执行暂时停止，并移动到操作系统调度程序管理的优先级队列的末尾。

也就是说，当你让出一个线程时，你本质上是对你的操作系统说以下内容："嘿！你能暂时停止执行这个线程，稍后再回来继续吗？"。你也可以将这个让出操作解释为："你能降低这个线程的优先级，专注于做其他事情吗？"。所以这个让出操作也是你停止特定线程的一种方式，这样你就可以工作并优先处理其他线程。

重要的是要说，让出线程如今是一个"不太常见"的线程操作。换句话说，没有多少程序员在生产中使用让出，仅仅是因为很难使用这个操作并使其正常工作，而且还有更好的替代方案。大多数程序员更喜欢使用`join()`。事实上，大多数时候，当你看到有人在某些代码示例中使用这个"让出"操作时，他们通常这样做是为了帮助调试应用程序中的竞态条件。也就是说，这个"让出"操作现在主要用作调试工具。

无论如何，如果你想让出一个线程，只需从它调用`yield()`方法，像这样：

```zig
thread.yield();
```

## 线程中的常见问题

### 死锁

当两个或多个线程永远被阻塞，等待彼此释放资源时，就会发生死锁。这通常发生在涉及多个锁时，并且获取它们的顺序没有得到很好的管理。

下面的代码示例演示了死锁情况。在这个例子中，我们有两个执行两个不同函数（`work1()`和`work2()`）的不同线程。我们还有两个独立的互斥锁。如果你编译并运行这个代码示例，你会注意到程序只是无限期地运行，没有结束。

当我们查看第一个线程（执行`work1()`函数）时，我们可以注意到这个函数首先获取`mut1`锁。因为这是在这个线程内执行的第一个操作，这是程序中创建的第一个线程。之后，函数睡眠1秒，模拟某种类型的工作，然后，函数尝试获取`mut2`锁。

另一方面，当我们查看第二个线程（执行`work2()`函数）时，我们可以看到这个函数首先获取`mut2`锁。因为当这个线程被创建并尝试获取这个`mut2`锁时，第一个线程仍在"睡眠1秒"这一行上睡眠。获取`mut2`后，`work2()`函数也睡眠1秒，模拟某种类型的工作，然后函数尝试获取`mut1`锁。

这创建了死锁情况，因为在两个线程中"睡眠1秒"行之后，线程1试图获取`mut2`锁，但这个锁当前正被线程2使用。然而，在这个时刻，线程2也试图获取`mut1`锁，它当前正被线程1使用。因此，两个线程最终永远等待。等待它们的同伴释放它们想要获取的锁。

```zig
var mut1: Mutex = .{}; var mut2: Mutex = .{};
fn work1() !void {
    mut1.lock();
    Thread.sleep(1 * std.time.ns_per_s);
    mut2.lock();
    _ = try stdout.write("Doing some work 1\n");
    mut2.unlock(); mut1.unlock();
}

fn work2() !void {
    mut2.lock();
    Thread.sleep(1 * std.time.ns_per_s);
    mut1.lock();
    _ = try stdout.write("Doing some work 1\n");
    mut1.unlock(); mut2.unlock();
}

pub fn main() !void {
    const thr1 = try Thread.spawn(.{}, work1, .{});
    const thr2 = try Thread.spawn(.{}, work2, .{});
    thr1.join();
    thr2.join();
}
```

### 不调用`join()`或`detach()`

当你不对线程调用`join()`或`detach()`时，这个线程就变成了"僵尸线程"，因为它没有明确的"返回点"。你也可以将此解释为："没有人正确负责管理线程"。当我们不确定线程是_可加入_还是_分离_时，没有人负责处理这个线程的返回值，也没有人负责清除（或释放）与这个线程关联的资源。

你不想处于这种情况，所以记得始终在你创建的线程上使用`join()`或`detach()`。当你不使用这些方法之一时，我们失去了对线程的控制，它的资源永远不会被释放（即你在系统中泄漏了资源）。

### 取消或终止特定线程

当我们考虑`pthreads` C库时，有一种可能的方法可以异步终止或取消线程，即通过`pthread_kill()`函数向线程发送`SIGTERM`信号。但像这样取消线程是不好的。这是危险的坏。因此，Zig的线程实现没有类似的函数，或者，没有类似的方法来异步取消或终止线程。

因此，如果你想在Zig中在执行过程中取消线程，那么你可以采取的一个好策略是将控制流与`join()`结合使用。更具体地说，你可以围绕while循环设计你的线程，该循环不断检查线程是否应该继续运行。如果是时候取消线程，我们可以让while循环中断，并通过调用`join()`将线程与主线程加入。

下面的代码示例在某种程度上演示了这种策略。在这里，我们使用控制流来中断while循环，并比我们最初计划的更早退出线程。这个例子还演示了我们如何在Zig中使用原子对象，使用我们在[第16.6.2节](https://pedropark99.github.io/zig-book/Chapters/14-threads.html#sec-atomic-operation)中提到的`Value()`泛型函数。

```zig
const std = @import("std");
const Thread = std.Thread;
var stdout_buffer: [1024]u8 = undefined;
var stdout_writer = std.fs.File.stdout().writer(&stdout_buffer);
const stdout = &stdout_writer.interface;
var running = std.atomic.Value(bool).init(true);
var counter: u64 = 0;

fn do_more_work() void {
    Thread.sleep(2 * std.time.ns_per_s);
}
fn work() !void {
    while (running.load(.monotonic)) {
        for (0..10000) |_| { counter += 1; }
        if (counter < 15000) {
            _ = try stdout.write(
                "Time to cancel the thread.\n"
            );
            running.store(false, .monotonic);
        } else {
            _ = try stdout.write("Time to do more work.\n");
            do_more_work();
            running.store(false, .monotonic);
        }
    }
    try stdout.flush();
}

pub fn main() !void {
    const thread = try Thread.spawn(.{}, work, .{});
    thread.join();
}
```

```
Time to cancel the thread.
```

---

## 脚注

1.   [https://github.com/ziglang/zig/issues/18810](https://github.com/ziglang/zig/issues/18810)[↩︎](https://pedropark99.github.io/zig-book/Chapters/14-threads.html#fnref1)

2.   [https://www.youtube.com/watch?v=7ENFeb-J75k&ab_channel=Computerphile](https://www.youtube.com/watch?v=7ENFeb-J75k&ab_channel=Computerphile)[↩︎](https://pedropark99.github.io/zig-book/Chapters/14-threads.html#fnref2)
